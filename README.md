<a name="readme-top"></a>
# ClÃºster Hadoop + Kafka en Docker

Este repositorio contiene un entorno completo de desarrollo para **Big Data** que integra un clÃºster Hadoop (HDFS + YARN) con Apache Kafka, diseÃ±ado para procesamiento distribuido y streaming de datos en tiempo real.

## ğŸš€ CaracterÃ­sticas  

- ğŸ³ **Entorno Dockerizado Simplificado**: Docker Compose optimizado con YAML anchors para fÃ¡cil mantenimiento
- ğŸ“ **ClÃºster Hadoop Completo**: 
  - HDFS con 1 NameNode y 2 DataNodes
  - YARN con ResourceManager y NodeManager
  - ConfiguraciÃ³n lista para MapReduce
- ğŸ“¡ **Stack Kafka Completo**:
  - Apache Kafka con Zookeeper
  - Kafka Connect con conector HDFS preinstalado
  - Kafka UI para administraciÃ³n visual
- ğŸ”’ **VolÃºmenes Persistentes**: Datos de Hadoop almacenados en volÃºmenes Docker nombrados
- âš¡ **Red Simplificada**: ComunicaciÃ³n entre servicios mediante DNS de Docker
- ğŸ“ **Scripts Optimizados**: InicializaciÃ³n robusta con manejo de errores
- ğŸ›¡ï¸ **ConfiguraciÃ³n de Solo Lectura**: Archivos de configuraciÃ³n y scripts montados en modo read-only 


## ğŸ“‚ Estructura del Proyecto  

```
ğŸ“‚ S3-Kafka/
â”œâ”€â”€ ğŸ“„ docker-compose.yml              # ConfiguraciÃ³n principal del clÃºster
â”œâ”€â”€ ğŸ“„ dockerfile                      # Imagen personalizada para YARN (Java 11)
â”œâ”€â”€ ğŸ“„ Dockerfile.kafka-connect        # Imagen con conector HDFS para Kafka
â”œâ”€â”€ ğŸ“„ README.md                       # Este archivo
â”‚
â”œâ”€â”€ ğŸ“‚ hadoop_config/                  # ConfiguraciÃ³n de Hadoop
â”‚   â”œâ”€â”€ ğŸ“„ core-site.xml              # ConfiguraciÃ³n central de Hadoop
â”‚   â”œâ”€â”€ ğŸ“„ hdfs-site.xml              # ConfiguraciÃ³n de HDFS
â”‚   â”œâ”€â”€ ğŸ“„ yarn-site.xml              # ConfiguraciÃ³n de YARN
â”‚   â”œâ”€â”€ ğŸ“„ mapred-site.xml            # ConfiguraciÃ³n de MapReduce
â”‚   â”œâ”€â”€ ğŸ“„ capacity-scheduler.xml     # ConfiguraciÃ³n del scheduler de YARN
â”‚   â””â”€â”€ ğŸ“„ log4j.properties           # ConfiguraciÃ³n de logs
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                        # Scripts de inicializaciÃ³n
â”‚   â”œâ”€â”€ ğŸ“„ start-hdfs.sh              # Inicia el NameNode
â”‚   â”œâ”€â”€ ğŸ“„ init-datanode.sh           # Inicia los DataNodes
â”‚   â”œâ”€â”€ ğŸ“„ start-yarn.sh              # Inicia el ResourceManager
â”‚   â””â”€â”€ ğŸ“„ start-nodemanager.sh       # Inicia el NodeManager
â”‚
â”œâ”€â”€ ğŸ“‚ src/                            # CÃ³digo fuente
â”‚   â””â”€â”€ ğŸ“‚ prod-cons/                 # Productores y consumidores de Kafka
â”‚       â”œâ”€â”€ ğŸ“‚ json/                  # VersiÃ³n con mensajes JSON
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ producer_json.py
â”‚       â”‚   â””â”€â”€ ğŸ“„ consumer_json.py
â”‚       â””â”€â”€ ğŸ“‚ plain/                 # VersiÃ³n con mensajes de texto plano
â”‚           â”œâ”€â”€ ğŸ“„ producer.py
â”‚           â””â”€â”€ ğŸ“„ consumer.py
â”‚
â””â”€â”€ ğŸ“‚ data/                           # Directorio para datos de prueba
    â””â”€â”€ ğŸ“„ README.txt
```

## ğŸ› ï¸ Requisitos  

- **Docker** y **Docker Compose** instalados en el sistema
- **RAM**: MÃ­nimo 6GB libres (recomendado 8GB+)
- **Espacio en disco**: Al menos 10GB libres para imÃ¡genes y volÃºmenes
- **Sistema Operativo**: Windows, Linux o macOS con Docker Desktop

## âš¡ InstalaciÃ³n y Uso  

### 1ï¸âƒ£ Iniciar el ClÃºster

```bash
# Construir e iniciar todos los servicios
docker-compose up -d --build

# Ver el estado de los contenedores
docker ps

# Ver logs de un servicio especÃ­fico
docker-compose logs -f namenode
docker-compose logs -f kafka
```

### 2ï¸âƒ£ Acceder a las Interfaces Web

Una vez iniciados los servicios, puedes acceder a:

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **NameNode UI** | http://localhost:9870 | Interfaz web de HDFS |
| **YARN ResourceManager** | http://localhost:8088 | GestiÃ³n de aplicaciones YARN |
| **NodeManager UI** | http://localhost:8042 | Estado del NodeManager |
| **Kafka UI** | http://localhost:8080 | AdministraciÃ³n de Kafka |
| **Kafka Connect** | http://localhost:8083 | API REST de Kafka Connect |

### 3ï¸âƒ£ Interactuar con los Servicios

**Acceder al NameNode:**
```bash
docker exec -it namenode bash
```

**Acceder a Kafka:**
```bash
docker exec -it kafka bash
```

**Acceder a Kafka Connect:**
```bash
docker exec -it kafka-connect bash
```

<p align="right">(<a href="#readme-top">Volver arriba</a>)</p>

## ğŸ“Œ Comandos Ãštiles  

### HDFS (desde el contenedor namenode)

```bash
# Listar archivos en HDFS
hdfs dfs -ls /

# Crear un directorio
hdfs dfs -mkdir -p /user/hadoop/data

# Subir un archivo a HDFS
hdfs dfs -put archivo.txt /user/hadoop/data/

# Descargar un archivo de HDFS
hdfs dfs -get /user/hadoop/data/archivo.txt .

# Ver el contenido de un archivo
hdfs dfs -cat /user/hadoop/data/archivo.txt

# Ver el estado del clÃºster
hdfs dfsadmin -report

# Verificar la salud del sistema de archivos
hdfs fsck /

# Salir del Safe Mode (si es necesario)
hdfs dfsadmin -safemode leave
```

### Kafka (desde el contenedor kafka)

```bash
# Listar topics
kafka-topics --bootstrap-server localhost:9092 --list

# Crear un topic
kafka-topics --bootstrap-server localhost:9092 --create --topic test --partitions 3 --replication-factor 1

# Describir un topic
kafka-topics --bootstrap-server localhost:9092 --describe --topic test

# Producir mensajes (consola)
kafka-console-producer --bootstrap-server localhost:9092 --topic test

# Consumir mensajes (consola)
kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning

# Eliminar un topic
kafka-topics --bootstrap-server localhost:9092 --delete --topic test
```

### Docker Compose

```bash
# Iniciar todos los servicios
docker-compose up -d

# Detener todos los servicios
docker-compose down

# Detener y eliminar volÃºmenes (Â¡cuidado! elimina datos)
docker-compose down -v

# Ver logs de todos los servicios
docker-compose logs -f

# Reconstruir un servicio especÃ­fico
docker-compose up -d --build namenode

# Reiniciar un servicio
docker-compose restart kafka
```

<p align="right">(<a href="#readme-top">Volver arriba</a>)</p>


## ğŸ—ï¸ Arquitectura del Sistema

### Stack Kafka
- **Zookeeper**: CoordinaciÃ³n y gestiÃ³n de metadatos de Kafka
- **Kafka**: Broker de mensajerÃ­a para streaming de datos
- **Kafka Connect**: IntegraciÃ³n con HDFS mediante conector preinstalado
- **Kafka UI**: Interfaz grÃ¡fica para administraciÃ³n y monitoreo

### Stack Hadoop
- **NameNode**: Nodo maestro de HDFS que gestiona los metadatos
- **DataNode1 y DataNode2**: Nodos de almacenamiento distribuido (replicaciÃ³n x2)
- **ResourceManager**: Gestor de recursos de YARN
- **NodeManager**: Ejecutor de tareas en el clÃºster YARN

### Red y ComunicaciÃ³n
- Todos los servicios comparten la red `cluster_network`
- ComunicaciÃ³n mediante nombres de host (DNS de Docker)
- No se requieren IPs estÃ¡ticas

## ğŸ¯ Casos de Uso

### 1. Procesamiento Batch con MapReduce
- Almacena datos en HDFS
- Ejecuta jobs MapReduce con YARN
- Analiza grandes volÃºmenes de datos

### 2. Streaming en Tiempo Real
- Produce mensajes a Kafka
- Consume y procesa streams
- Integra con HDFS mediante Kafka Connect

### 3. Pipeline HÃ­brido
- Ingesta datos en tiempo real con Kafka
- Almacena en HDFS mediante Kafka Connect
- Procesa con MapReduce para anÃ¡lisis histÃ³rico

## ğŸ“ Mejoras Implementadas

âœ… **Docker Compose Simplificado**
- Uso de YAML anchors para eliminar duplicaciÃ³n
- VolÃºmenes Docker nombrados en lugar de bind mounts
- Red bridge simple sin IPs estÃ¡ticas

âœ… **Scripts Optimizados**
- Manejo de errores con `set -e`
- InicializaciÃ³n segura de directorios
- SeparaciÃ³n correcta de responsabilidades

âœ… **ConfiguraciÃ³n Mejorada**
- Comentarios en inglÃ©s para mejor comprensiÃ³n
- Formato consistente en todos los archivos XML
- Valores optimizados para entorno de desarrollo

âœ… **Seguridad**
- Montajes de solo lectura para configs y scripts
- PrevenciÃ³n de modificaciones accidentales

## â“ FAQ  

### **Error: "unexpected end of file" en scripts**
Los scripts pueden tener formato de lÃ­nea Windows. ConviÃ©rtelos:
```bash
# Verificar el formato
cat -A scripts/start-hdfs.sh

# Convertir si ves ^M al final de las lÃ­neas
sed -i 's/\r$//' scripts/*.sh
```

### **NameNode en Safe Mode**
El NameNode entra en Safe Mode al inicio. Para salir:
```bash
docker exec -it namenode bash
hdfs dfsadmin -safemode leave
```

### **Los DataNodes no se conectan**
Verifica que el NameNode estÃ© completamente inicializado:
```bash
docker-compose logs namenode
hdfs dfsadmin -report
```

### **Kafka no puede conectarse a Zookeeper**
AsegÃºrate de que Zookeeper estÃ© funcionando:
```bash
docker-compose logs zookeeper
docker exec -it zookeeper bash
echo stat | nc localhost 2181
```

### **Los volÃºmenes persisten datos entre reinicios**
SÃ­, los volÃºmenes Docker nombrados mantienen los datos. Para limpiar:
```bash
# Ver volÃºmenes
docker volume ls

# Eliminar todo (Â¡cuidado!)
docker-compose down -v
```

## ğŸ“ Notas Importantes

- âš ï¸ Este entorno estÃ¡ configurado para **desarrollo y pruebas**, no para producciÃ³n
- ğŸ”’ La seguridad estÃ¡ deshabilitada para facilitar el desarrollo
- ğŸ“Š El factor de replicaciÃ³n de HDFS es 2 (requiere ambos DataNodes)
- ğŸ”„ Los volÃºmenes Docker persisten datos entre reinicios
- ğŸ› ï¸ Puedes escalar aÃ±adiendo mÃ¡s DataNodes en `docker-compose.yml`


## ğŸš€ PrÃ³ximos Pasos

DespuÃ©s de tener el clÃºster funcionando, puedes:

1. **Explorar HDFS**: Sube archivos y experimenta con comandos
2. **Ejecutar Jobs MapReduce**: Procesa datos distribuidos
3. **Crear Topics en Kafka**: Implementa productores y consumidores
4. **Configurar Kafka Connect**: Conecta Kafka con HDFS
5. **Desarrollar Aplicaciones**: Usa Python para interactuar con ambos sistemas

## ğŸ“– Referencias  

- [DocumentaciÃ³n oficial de Hadoop](https://hadoop.apache.org/docs/stable/)  
- [DocumentaciÃ³n oficial de Apache Kafka](https://kafka.apache.org/documentation/)
- [Kafka Connect HDFS Connector](https://docs.confluent.io/kafka-connect-hdfs/current/index.html)
- [Docker Hub - Hadoop Images](https://hub.docker.com/r/apache/hadoop)
- [Docker Hub - Confluent Platform](https://hub.docker.com/u/confluentinc)

## ğŸ‘¥ Contribuciones

Â¿Encontraste un bug o tienes una sugerencia? Â¡Abre un issue o pull request!

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Consulta el archivo `LICENSE` para mÃ¡s detalles.

<p align="right">(<a href="#readme-top">Volver arriba</a>)</p>

---

**Desarrollado para la asignatura IngenierÃ­a de Datos: Big Data**  
*MÃ¡ster en IngenierÃ­a del Software - Cloud, Datos y GestiÃ³n TI*  
*Universidad de Sevilla*